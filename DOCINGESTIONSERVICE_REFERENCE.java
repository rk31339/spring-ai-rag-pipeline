package com.rk.ai.rag.service;\n\nimport com.rk.ai.rag.exception.DocumentProcessingException;\nimport com.rk.ai.rag.model.UploadResponse;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.vectorstore.VectorStore;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.multipart.MultipartFile;\n\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.time.LocalDateTime;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\n\n@Service\npublic class DocumentIngestionService {\n    \n    private static final Logger logger = LoggerFactory.getLogger(DocumentIngestionService.class);\n    private static final long MAX_FILE_SIZE = 10 * 1024 * 1024;\n    private static final List<String> ALLOWED_EXTENSIONS = List.of(\".md\", \".txt\", \".markdown\");\n    \n    private final VectorStore vectorStore;\n    private final ChunkingService chunkingService;\n    \n    public DocumentIngestionService(VectorStore vectorStore, ChunkingService chunkingService) {\n        this.vectorStore = vectorStore;\n        this.chunkingService = chunkingService;\n    }\n    \n    public UploadResponse ingestDocuments(MultipartFile[] files) {\n        String jobId = UUID.randomUUID().toString();\n        logger.info(\"Starting document ingestion job: {}\", jobId);\n        \n        UploadResponse response = new UploadResponse(jobId, \"PROCESSING\", \"Document ingestion started\");\n        response.setTotalFiles(files.length);\n        \n        List<UploadResponse.DocumentInfo> documentInfos = new ArrayList<>();\n        int processedCount = 0;\n        int totalChunks = 0;\n        \n        for (MultipartFile file : files) {\n            UploadResponse.DocumentInfo docInfo = new UploadResponse.DocumentInfo(\n                UUID.randomUUID().toString(),\n                file.getOriginalFilename(),\n                file.getSize()\n            );\n            \n            try {\n                validateFile(file);\n                int chunks = processDocument(file, docInfo.getDocumentId());\n                \n                docInfo.setChunks(chunks);\n                docInfo.setStatus(\"SUCCESS\");\n                processedCount++;\n                totalChunks += chunks;\n                \n                logger.info(\"Successfully processed document: {} ({} chunks)\", \n                    file.getOriginalFilename(), chunks);\n                \n            } catch (DocumentProcessingException e) {\n                logger.error(\"Failed to process document: {}\", file.getOriginalFilename(), e);\n                docInfo.setStatus(\"FAILED\");\n                docInfo.setErrorMessage(e.getMessage());\n                \n            } catch (Exception e) {\n                logger.error(\"Unexpected error processing document: {}\", file.getOriginalFilename(), e);\n                docInfo.setStatus(\"FAILED\");\n                docInfo.setErrorMessage(\"Unexpected error: \" + e.getMessage());\n            }\n            \n            documentInfos.add(docInfo);\n        }\n        \n        response.setProcessedFiles(processedCount);\n        response.setTotalChunks(totalChunks);\n        response.setDocuments(documentInfos);\n        \n        if (processedCount == files.length) {\n            response.setStatus(\"COMPLETED\");\n            response.setMessage(String.format(\"Successfully processed all %d documents (%d chunks)\", \n                processedCount, totalChunks));\n        } else if (processedCount == 0) {\n            response.setStatus(\"FAILED\");\n            response.setMessage(\"Failed to process any documents\");\n        } else {\n            response.setStatus(\"PARTIAL_SUCCESS\");\n            response.setMessage(String.format(\"Processed %d/%d documents (%d chunks)\", \n                processedCount, files.length, totalChunks));\n        }\n        \n        logger.info(\"Completed ingestion job {}: {}\", jobId, response.getStatus());\n        return response;\n    }\n    \n    private int processDocument(MultipartFile file, String documentId) {\n        String filename = file.getOriginalFilename();\n        \n        try {\n            String content = extractContent(file);\n            Map<String, Object> metadata = createMetadata(file, documentId);\n            List<Document> chunks = chunkDocument(content, filename, metadata);\n            storeChunks(chunks, filename);\n            \n            return chunks.size();\n            \n        } catch (IOException e) {\n            throw new DocumentProcessingException(\n                \"Failed to read file content\",\n                filename,\n                DocumentProcessingException.ProcessingStage.FILE_READING,\n                e\n            );\n        } catch (Exception e) {\n            if (e instanceof DocumentProcessingException) {\n                throw e;\n            }\n            throw new DocumentProcessingException(\n                \"Unexpected error during processing\",\n                filename,\n                DocumentProcessingException.ProcessingStage.TEXT_EXTRACTION,\n                e\n            );\n        }\n    }\n    \n    private void validateFile(MultipartFile file) {\n        String filename = file.getOriginalFilename();\n        \n        if (filename == null || filename.trim().isEmpty()) {\n            throw new DocumentProcessingException(\n                \"Filename is empty\",\n                \"unknown\",\n                DocumentProcessingException.ProcessingStage.FILE_READING\n            );\n        }\n        \n        if (file.getSize() > MAX_FILE_SIZE) {\n            throw new DocumentProcessingException(\n                String.format(\"File size (%d bytes) exceeds maximum allowed size (%d bytes)\", \n                    file.getSize(), MAX_FILE_SIZE),\n                filename,\n                DocumentProcessingException.ProcessingStage.FILE_READING\n            );\n        }\n        \n        boolean validExtension = ALLOWED_EXTENSIONS.stream()\n            .anyMatch(ext -> filename.toLowerCase().endsWith(ext));\n        \n        if (!validExtension) {\n            throw new DocumentProcessingException(\n                String.format(\"File type not supported. Allowed types: %s\", ALLOWED_EXTENSIONS),\n                filename,\n                DocumentProcessingException.ProcessingStage.FILE_READING\n            );\n        }\n        \n        if (file.isEmpty()) {\n            throw new DocumentProcessingException(\n                \"File is empty\",\n                filename,\n                DocumentProcessingException.ProcessingStage.FILE_READING\n            );\n        }\n    }\n    \n    private String extractContent(MultipartFile file) throws IOException {\n        byte[] bytes = file.getBytes();\n        String content = new String(bytes, StandardCharsets.UTF_8);\n        \n        if (content.trim().isEmpty()) {\n            throw new DocumentProcessingException(\n                \"File content is empty or contains only whitespace\",\n                file.getOriginalFilename(),\n                DocumentProcessingException.ProcessingStage.TEXT_EXTRACTION\n            );\n        }\n        \n        return content;\n    }\n    \n    private Map<String, Object> createMetadata(MultipartFile file, String documentId) {\n        Map<String, Object> metadata = new HashMap<>();\n        metadata.put(\"filename\", file.getOriginalFilename());\n        metadata.put(\"file_size\"
